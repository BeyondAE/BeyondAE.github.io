---
title : 엘라스틱 과거 현재 미래
description :
date : 2017-12-12
categories :
- elastic
tags :
- elastic
---

# 5.0
- Full sendbox scripting 지원을 위해 painless언어를 만들었다.
- 샤드 집중을 해소하기 위해 노력했다.
- range type이 생겨남. (1~10)

# the next
## 뼈 아픈 부분들
- Cluster운영, 클러스터링
- 노드 복구 동작

### Scaling
- more clusters, not big clusters
  - 기존에 Tribe Node를 지원했었다.
    - Tribe node가 클러스터 상태들을 가져와 합쳐 관리했었다.
    - 클러스터 상태를 가져오기 위해 설정하는 부분이 static했다.
    - Tribe node는 색인이 불가능했다.
  - Cross Cluster search
    - 클러스터는 namespace를 만듦
    - 각 클러스터에 접근 전, 네임영역을 보고 접근한다.
    - 동적 셋팅이 가능해, 붙을 노드를 붙이고 빼고가 가능
    - 키바나가 바로 붙을 수도 있다.
- major 버전 업데이트
  - 보통 업그레이드 시, 루씬이 업데이트 한다.
  - Migration assistance API로 마이그레이션을 지원 ( x-pack)
  - Rolling Update를 해야한다.
  - 서로 다른 버전은, Cross Cluster Search가 가능함.
- Slow Recovery
  - 어떻게 저장하지?
    - mem -> transaction log -> segment(store)
    - 리플리카 : client -> primary shard -> replica shard
    - primary와 replica의 형태를 함꼐하기 위해 많은 시간을 들였다.
      - 기존 : replica가 죽고 복구되면 primary에서 다시 복제 해왔다. 느려..
      - 현재 : Transaction Log를 통해 형태를 유지하고, 레플리카 복구시 받았던 data이후만 복구, segment가 되면 된 부분까지의 index를 비교해 이 후만 유지
- 데이터 파싱과 disk 사용
  - DocValues : Culomnar
  ![docvalue]()
    -  null이 많아지는데 이걸 없앴다.
  - Sparse Doc Values
    - matrix에서 들어오는 값은 필드가 디게 많은데, 막상 쓰는 건 얼마 안 된다.
    - 재색인 해보면 용량이 상당히 줄어있는 것을 알 수 있다.
---
# Ingest
컨설팅 아키텍쳐
## ElasticSearch API
- injestnode에서 전송을 한다. store node나 하툽
## LogStash
- Dead 이벤트들은 DLQ에 저장된다.
- Multiple Pipeline
# Data Sources
- matrix는 k8s를 모니터링 가능 하다.
- Packbeat
- Metricbeat modules
- arcSight module

---
# Machine Learning Deep Dive
- nginx log -> file beats -> ml
- 평범한 패턴에선 아무 추론도 없고, 엇나가는 패턴에서 부터 과거 패턴 포함, 분석을 진행
- 최소 2일의 데이터가 있어야 한다.
- 미래 타임시리즈를 통해 입력에 대한 출력의 확률을 도출한다.(forecast)
- 하고 싶으면 타임시리즈 잡을 하나 만들어서 해보셈
- matrix 데이터가 여러 개면, 수만 개면 수만개의 타임시리즈를 돌리면 된다.
- advanced에서 모든 것을 할 수도 있다.
- 머신러닝 job을 Pack으로 제공할 수도 있다.
- Data visulariser로 자신이 잘 모르겠다는 데이터를 시각적으로 볼 수 있다.
