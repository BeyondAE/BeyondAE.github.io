---
title : 소스 교육
description :
date : 2017-12-12
categories :
- elastic
tags :
- elastic
---

# 흐름
## LogStash
- 다양한 곳으로 데이터 보낼 수 있다.
[데이터를 여러곳에서 받아서 보낼 수 있다.]()

## ES-Hdoop
- 하둡의 파이프에서 받아서 처리할 수가 있다.

## 전체적인 그림
[시스템 아키텍쳐]()

## X-Pack

### Security
- 엘라스틱은 http 으로 누구나 접근이 됨
- 계정 시스템을 지원할 수 있게 한다.
- https 지원
- 감사로그를 지원한다.

### Alerting
- 특정 결과에 따른 알림을 주는 기능
- Email, Slack, webhook
- 별개의 시스템 모니터링
  - 지정 수치보다 낮으면, 알림

### Monitering
- 클러스터에 대한 모니터링
  - 얼마나 많이 리소스를 사용하고 있는지.
  - Java heap 수치, GC 동작
- 무료 신청하면 사용이 가능하다.

### 리포팅
- 키바나 화면을 PDF로
- CSV로 포팅

### Graph
- 관계도 분석이 가능하게(OrientDB의 뷰와 똑같다.)

### Machine Learning
- 이상징후 탐지에 특화돼 있다.

### Elastic Cloud Enterprise
- 자사 IDC에 구축할 수 있는 패키지를 판매하고 있다.


# Elastic Deep Dive
- 루씬 기반, 아파치 2.0 라이센스

## 클러스터링 과정
- 데이터를 샤드 단위로 분리해서 저장
![그림]
- 프라이머리와 리플리카로 구분됨.
- 샤드 - 노드 - 클러스터 단위
- 노드 하나가 죽으면 죽은 노드 안의 샤드는 다른 노드에 분할해서 리플리카를 생성함.

### 클러스터
- 클러스터가 다르면 관섭을 안 한다.

### 노드
- 엘라스틱서치를 구성하는 하나의 단위 프로세스

### Master & Data 노드
- 마스터 : 클러스터 상태 정보를 관리합니다.
- 데이터 : 데이터 입/출력, 검색을 수행
- 색인정보 -> 마스터 -> 데이터 노드로 이동
- yaml로 마스터 노드의 부담을 덜기 위해 여러 마스터 노드로 설정이 가능하다.
  - 보통은 제일 처음 실행된 노드가 마스터
  - 마스터 노드가 죽으면 클러스터가 운영이 안 된다.
  - 마스터 노드가 죽으면 복제해서 다른 마스터가 받아감
  - 보통은 마스터 노드 3개 설정 권장

### 샤드 & 레플리카
- 샤드 : 루씬 검색 인스턴스
- 레플리카 : 데이터 무결성 유지를 위한 샤드의 복사본
  - 동적으로 유지가 가능하다.
  - 여러 쿼리가 있을 때는 늘여서 병렬 처리.

## 사용
- REST API, JSON
- host:port/index/type/documentid
- 한 인덱스에 하나의 타입으로

### bulk
- 대용량은 벌크를 사용해
- 벌크를 사용하고 안 하고는 속도가 10배 차이

### search

### FullText 검색
- 위키는 ElasticSearch를 사용한다.
- 문장을 분리해서 저장
- 단어(Token)로 저장하고 DOC위치를 보고 찾아 들어감
- 붎용어는 다 제거한다.( the,a )
- 다음, 형태소 분석(Jumping -> Junp)

### analyze API로 분석이 가능

### 검색 과정
- 검색어도 색인 관정을 거친다.
![RDBMS와 비교]()
- 로그 저장시 삭제 단위로 애초에 저장하라.

### Term 확인
- Termvector

### match

### term 검색
- 정확하게 일치하는 것을 찾음

### Aggregation
- search API에서 쿼리와 함께 사용함.
- Bucket : Document 집단 단위의 버킷 생성
- Metric 도큐먼트 집단에 대한 하나 또는 그 이상으 ㅣ계산된 수치를 포함
- Pipeline : aggs 결과에 대한 새로운 계산을 실행

### Query Phase
- 검색 명령 받은 노드는 모든 샤드에
- 샤드들은 요청된 크기만큼의 검색 결과 큐를 노드로 리턴함.
- doc id와 랭킹을 매김
### Fetch Phase
- 랭킹에서 10개 정도를 잘라서 해당을 가진 노드에서... 를 하고

# 실시간 검색
- 데이터가 들어오면 1초 후에 이행이된다.
- 세스먼트가 1초 마다 만들어짐.
- 세그먼트는 삭제가 안 되고 주기적으로 병합이 된다.

## 삭제 및 병합
- 최근 생성파일은 지울 떄 무리가 없는데
- 오래된 것은 비싸다.
- Lucene segment merge 를 검색

# 실습
- bin/ElasticSearch -p옵션으로 파일애 pid를 저장해 킬하는 용도로 씀
- .Kibana 인덱스?
- 버전 릴리즈시 Stack이 전부 같이 버전 업돼 배포된다.
- LogStash
  - Pileine.yaml이 새로 생겼다.
  - automethic : true
  - weblog.conf 파일 생성
    - input과 Output을 설정.
    - LogStash -f weblog.conf //설정임
    - 출력에 코덱을 달아준다.
      ![코덱 설정 ppt]()
      - rubydebug가 편하다.
    - Grok Filter
      - regex를 편하게 해둔 것이다.
      - Doc을 보자
      - Pattern들은 git에 있다.
      - CombineApachLog를 사용하면 여기선 적용이 가능함.
    - GeoIP
      - Ip설정을 통해 timezone등이 나타난다.
    - useragent
      - 운영체제별 브라우저정보를 가져올 수 있다.
      - Grok를 먼저써야함ㅋㅋㅋ
    - Mutate
      - bytes를 표시해줌.
- 출력을 ElasticSearch로 설정하면
  - 키바나에서 읽을 수 있음
- FileBeat
  - FileBeat -e(이걸로 화면에 출력) -C(로 현재 경로 외의 yaml 경로 설정 가능)
  - 실행하면 ElasticSearch를 찾는다.
    - FileBeat.yaml에서 출력 경로를 LogStash로 변경이 가능하다.
    - FileBeat이 한 번 읽은 파일이면 읽지 않는다.
